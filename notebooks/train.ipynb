{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook prepare enviroment inside ur google colab notebook, like cloning actual code, downloading data, setuping tensortboard, and running the experiment*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q kaggle\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Choose the kaggle.json file that you downloaded\")\n",
    "files.upload()\n",
    "\n",
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "!kaggle competitions download -c cassava-leaf-disease-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r -f train_dataset\n",
    "!mkdir train_dataset\n",
    "!unzip -qq cassava-leaf-disease-classification.zip -d train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone code form GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'cassava-classification'...\n",
      "remote: Enumerating objects: 62, done.\u001b[K\n",
      "remote: Counting objects: 100% (62/62), done.\u001b[K\n",
      "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
      "remote: Total 62 (delta 22), reused 48 (delta 10), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (62/62), 20.31 KiB | 462.00 KiB/s, done.\n",
      "Branch 'catalyst_pipeline' set up to track remote branch 'catalyst_pipeline' from 'origin'.\n",
      "Switched to a new branch 'catalyst_pipeline'\n"
     ]
    }
   ],
   "source": [
    "!rm -r -f cassava-classification\n",
    "!rm -r -f src config requirements.txt\n",
    "!git clone https://github.com/alxmamaev/cassava-classification\n",
    "    \n",
    "# Replace branch name to that u need\n",
    "!cd cassava-classification && git checkout catalyst_pipeline\n",
    "!cp -r -f ./cassava-classification/config .\n",
    "!cp -r -f ./cassava-classification/src .\n",
    "!cp -r -f ./cassava-classification/requirements.txt .\n",
    "!rm -r -f ./cassava-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove logs if exists, and make if not exists\n",
    "!rm -r -f logs\n",
    "!mkdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download ngrok to tunnel port for jupyter\n",
    "!rm -r -f ngrok\n",
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip ngrok-stable-linux-amd64.zip\n",
    "!rm -r -f ngrok-stable-linux-amd64.zip\n",
    "!chmod +x ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tensorboard\n",
    "LOG_DIR = './logs'\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR)\n",
    ")\n",
    "\n",
    "# Run ngrok for making public URL\n",
    "get_ipython().system_raw('./ngrok http 6006 &')\n",
    "\n",
    "# Getting a public url\n",
    "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    " \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 * Epoch (train):   0% 0/268 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"/Users/alxmamaev/miniconda3/bin/catalyst-dl\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/alxmamaev/miniconda3/lib/python3.8/site-packages/catalyst/dl/__main__.py\", line 57, in main\n",
      "    COMMANDS[args.command].main(args, uargs)\n",
      "  File \"/Users/alxmamaev/miniconda3/lib/python3.8/site-packages/catalyst/dl/scripts/run.py\", line 132, in main\n",
      "    distributed_cmd_run(main_worker, args.distributed, args, unknown_args)\n",
      "  File \"/Users/alxmamaev/miniconda3/lib/python3.8/site-packages/catalyst/utils/scripts.py\", line 176, in distributed_cmd_run\n",
      "    worker_fn(*args, **kwargs)\n",
      "  File \"/Users/alxmamaev/miniconda3/lib/python3.8/site-packages/catalyst/dl/scripts/run.py\", line 127, in main_worker\n",
      "    runner.run_experiment(experiment)\n",
      "  File \"/Users/alxmamaev/miniconda3/lib/python3.8/site-packages/catalyst/core/runner.py\", line 828, in run_experiment\n",
      "    self._run_event(\"on_exception\")\n",
      "  File \"/Users/alxmamaev/miniconda3/lib/python3.8/site-packages/catalyst/core/runner.py\", line 757, in _run_event\n",
      "    getattr(callback, event)(self)\n",
      "  File \"/Users/alxmamaev/miniconda3/lib/python3.8/site-packages/catalyst/callbacks/exception.py\", line 34, in on_exception\n",
      "    raise exception\n",
      "  File \"/Users/alxmamaev/miniconda3/lib/python3.8/site-packages/catalyst/core/runner.py\", line 825, in run_experiment\n",
      "    self._run_experiment()\n",
      "  File \"/Users/alxmamaev/miniconda3/lib/python3.8/site-packages/catalyst/core/runner.py\", line 810, in _run_experiment\n",
      "    self._run_stage()\n",
      "  File \"/Users/alxmamaev/miniconda3/lib/python3.8/site-packages/catalyst/core/runner.py\", line 801, in _run_stage\n",
      "    self._run_epoch()\n",
      "  File \"/Users/alxmamaev/miniconda3/lib/python3.8/site-packages/catalyst/core/runner.py\", line 795, in _run_epoch\n",
      "    self._run_loader()\n",
      "  File \"/Users/alxmamaev/miniconda3/lib/python3.8/site-packages/catalyst/core/runner.py\", line 785, in _run_loader\n",
      "    for self.loader_batch_step, self.input in enumerate(self.loader):\n",
      "  File \"/Users/alxmamaev/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 435, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/Users/alxmamaev/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 475, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/Users/alxmamaev/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/Users/alxmamaev/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/Users/alxmamaev/Projects/cassava-classification/notebooks/src/dataset.py\", line 32, in __getitem__\n",
      "    image = cv2.resize(image, self.image_size)\n",
      "cv2.error: OpenCV(4.4.0) /private/var/folders/nz/vv4_9tw56nv9k3tkvyszvwg80000gn/T/pip-req-build-xi5c66nc/opencv/modules/imgproc/src/resize.cpp:3929: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "1/3 * Epoch (train):   0% 0/268 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run experiment\n",
    "\n",
    "!catalyst-dl run --config=config/train.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ta-da-da!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now u can check metrics at Tensorboard and download checkpoint from logs/checkpoints*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
